{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMJT6wvxzlaj1yBI300fhBi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pmj-chosim/OSSCA/blob/main/6_Cat_%26_Dogs_%EC%9D%B4%EB%AF%B8%EC%A7%80_%EB%B6%84%EB%A5%98_%EB%94%A5_%EB%9F%AC%EB%8B%9D_%EB%AA%A8%EB%8D%B8_%EC%83%9D%EC%84%B1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "do5rzSyeEtpZ",
        "outputId": "1f470bc1-b968-40d4-e91a-917a3d08f9c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1. 사진 구글링으로 다운받기"
      ],
      "metadata": {
        "id": "A9emMH-UHTb-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. 사이즈 일괄적으로 맞추기"
      ],
      "metadata": {
        "id": "bgxEwUqNHXz-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "def resize_crop_images(input_path, output_path, target_size):\n",
        "    if not os.path.exists(output_path):\n",
        "        os.makedirs(output_path)\n",
        "\n",
        "    for filename in os.listdir(input_path):\n",
        "        image_path = os.path.join(input_path, filename)\n",
        "        if os.path.isfile(image_path):\n",
        "            img = Image.open(image_path)\n",
        "            img = img.resize(target_size, Image.LANCZOS)\n",
        "            img.save(os.path.join(output_path, filename))\n",
        "\n",
        "# 입력 폴더 경로와 출력 폴더 경로 설정\n",
        "input_path = \"C:/Users/parkm/Desktop/저장\" # 입력 폴더 경로를 지정하세요.\n",
        "output_path = \"C:/Users/parkm/Desktop/저장\" # 출력 폴더 경로를 지정하세요.\n",
        "\n",
        "# 입력 shape 설정 (150x150으로 변경)\n",
        "target_size = (150, 150)\n",
        "\n",
        "resize_crop_images(input_path, output_path, target_size)\n"
      ],
      "metadata": {
        "id": "XKOYi16QHRCO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. 드라이브에 업로드 하기\n",
        ">좌측 마운트된 드라이브에 바로 업로드\n",
        "\n",
        "난 ex 폴더 밑에 dog, cat 폴더 파서 각 폴더에 dog,cat 리사이즈된 이미지 저장\n",
        "\n",
        "ex/\n",
        "\n",
        "   ├── cat/\n",
        "\n",
        "   |    ├── cat_image1.jpg\n",
        "\n",
        "   |    ├── cat_image2.jpg\n",
        "\n",
        "   |    ├── ...\n",
        "\n",
        "   |\n",
        "\n",
        "   └── dog/\n",
        "\n",
        "        ├── ..."
      ],
      "metadata": {
        "id": "2-Je94Y4Hoia"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. 딥러닝 학습 및 테스트"
      ],
      "metadata": {
        "id": "gZUwkWEQIjdD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# 이미지 크기와 경로 설정\n",
        "image_size = (150, 150)\n",
        "train_data_dir = \"/content/drive/MyDrive/ex\"\n",
        "\n",
        "# 데이터 전처리와 증강 설정\n",
        "train_data_gen = ImageDataGenerator(\n",
        "    rescale=1.0 / 255,  # 픽셀 값을 0과 1 사이로 정규화\n",
        "    shear_range=0.2,    # 이미지를 잘라내어 각도를 변화시킴\n",
        "    zoom_range=0.2,     # 이미지를 확대/축소\n",
        "    horizontal_flip=True  # 이미지를 좌우로 뒤집음\n",
        ")\n",
        "\n",
        "# 훈련 데이터 불러오기\n",
        "train_data = train_data_gen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=image_size,\n",
        "    batch_size=32,\n",
        "    class_mode='binary'  # 이진 분류 (개와 고양이)\n",
        ")\n",
        "\n",
        "# 딥러닝 모델 생성\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=Adam(learning_rate=1e-4),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# 모델 훈련\n",
        "model.fit(train_data, epochs=30)\n",
        "\n",
        "# 테스트 이미지 분류\n",
        "test_image_path1 = \"/content/drive/MyDrive/test1.jpeg\"  # 테스트할 이미지 파일 경로\n",
        "test_image_path2 = \"/content/drive/MyDrive/test2.jpeg\"  # 테스트할 이미지 파일 경로\n",
        "\n",
        "def classify_image(image_path):\n",
        "    img = tf.keras.preprocessing.image.load_img(image_path, target_size=image_size)\n",
        "    img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "    img_array = tf.expand_dims(img_array, 0)  # 모델의 입력 형태로 변환\n",
        "    predictions = model.predict(img_array)\n",
        "    if predictions[0][0] < 0.5:\n",
        "        return \"고양이\"\n",
        "    else:\n",
        "        return \"개\"\n",
        "\n",
        "result1 = classify_image(test_image_path1)\n",
        "result2 = classify_image(test_image_path2)\n",
        "print(f\"{test_image_path1}는 {result1}입니다.\")\n",
        "print(f\"{test_image_path2}는 {result2}입니다.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2XoCg8TF2nD",
        "outputId": "8b8121f5-4ba8-41cc-871a-68d0d478794e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20 images belonging to 3 classes.\n",
            "Epoch 1/30\n",
            "1/1 [==============================] - 4s 4s/step - loss: 0.6199 - accuracy: 0.5000\n",
            "Epoch 2/30\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.2283 - accuracy: 0.5000\n",
            "Epoch 3/30\n",
            "1/1 [==============================] - 1s 1s/step - loss: -0.1359 - accuracy: 0.5000\n",
            "Epoch 4/30\n",
            "1/1 [==============================] - 1s 1s/step - loss: -0.4994 - accuracy: 0.5000\n",
            "Epoch 5/30\n",
            "1/1 [==============================] - 1s 1s/step - loss: -0.9010 - accuracy: 0.5000\n",
            "Epoch 6/30\n",
            "1/1 [==============================] - 1s 1s/step - loss: -1.3175 - accuracy: 0.5000\n",
            "Epoch 7/30\n",
            "1/1 [==============================] - 2s 2s/step - loss: -1.7804 - accuracy: 0.5000\n",
            "Epoch 8/30\n",
            "1/1 [==============================] - 2s 2s/step - loss: -2.3007 - accuracy: 0.5000\n",
            "Epoch 9/30\n",
            "1/1 [==============================] - 2s 2s/step - loss: -2.9518 - accuracy: 0.5000\n",
            "Epoch 10/30\n",
            "1/1 [==============================] - 2s 2s/step - loss: -3.6407 - accuracy: 0.5000\n",
            "Epoch 11/30\n",
            "1/1 [==============================] - 1s 1s/step - loss: -4.4960 - accuracy: 0.5000\n",
            "Epoch 12/30\n",
            "1/1 [==============================] - 1s 1s/step - loss: -5.5105 - accuracy: 0.5000\n",
            "Epoch 13/30\n",
            "1/1 [==============================] - 1s 1s/step - loss: -6.6499 - accuracy: 0.5000\n",
            "Epoch 14/30\n",
            "1/1 [==============================] - 1s 1s/step - loss: -7.9510 - accuracy: 0.5000\n",
            "Epoch 15/30\n",
            "1/1 [==============================] - 1s 1s/step - loss: -9.4720 - accuracy: 0.5000\n",
            "Epoch 16/30\n",
            "1/1 [==============================] - 1s 1s/step - loss: -11.3506 - accuracy: 0.5000\n",
            "Epoch 17/30\n",
            "1/1 [==============================] - 1s 1s/step - loss: -13.6546 - accuracy: 0.5000\n",
            "Epoch 18/30\n",
            "1/1 [==============================] - 1s 1s/step - loss: -16.0348 - accuracy: 0.5000\n",
            "Epoch 19/30\n",
            "1/1 [==============================] - 2s 2s/step - loss: -18.6233 - accuracy: 0.5000\n",
            "Epoch 20/30\n",
            "1/1 [==============================] - 2s 2s/step - loss: -21.9196 - accuracy: 0.5000\n",
            "Epoch 21/30\n",
            "1/1 [==============================] - 1s 1s/step - loss: -25.8102 - accuracy: 0.5000\n",
            "Epoch 22/30\n",
            "1/1 [==============================] - 1s 1s/step - loss: -30.2572 - accuracy: 0.5000\n",
            "Epoch 23/30\n",
            "1/1 [==============================] - 1s 1s/step - loss: -35.2200 - accuracy: 0.5000\n",
            "Epoch 24/30\n",
            "1/1 [==============================] - 2s 2s/step - loss: -40.6001 - accuracy: 0.5000\n",
            "Epoch 25/30\n",
            "1/1 [==============================] - 1s 1s/step - loss: -47.2595 - accuracy: 0.5000\n",
            "Epoch 26/30\n",
            "1/1 [==============================] - 1s 1s/step - loss: -54.4712 - accuracy: 0.5000\n",
            "Epoch 27/30\n",
            "1/1 [==============================] - 1s 1s/step - loss: -63.3000 - accuracy: 0.5000\n",
            "Epoch 28/30\n",
            "1/1 [==============================] - 2s 2s/step - loss: -73.9430 - accuracy: 0.5000\n",
            "Epoch 29/30\n",
            "1/1 [==============================] - 2s 2s/step - loss: -82.9745 - accuracy: 0.5000\n",
            "Epoch 30/30\n",
            "1/1 [==============================] - 1s 1s/step - loss: -97.7692 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 109ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "/content/drive/MyDrive/test1.jpeg는 개입니다.\n",
            "/content/drive/MyDrive/test2.jpeg는 개입니다.\n"
          ]
        }
      ]
    }
  ]
}